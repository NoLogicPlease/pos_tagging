{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2ADs98pXS5A"
      },
      "source": [
        "#IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J_G319uWdaq"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import copy\n",
        "import os\n",
        "import re\n",
        "import tarfile\n",
        "import zipfile\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from urllib import request\n",
        "import collections\n",
        "import gensim\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import gensim.downloader as gloader\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94EeD6PDYehe"
      },
      "source": [
        "EMBEDDING_SIZE = 50"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBnbipknZFiz"
      },
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "    \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "    Args:\n",
        "        seed: the seed to use. \n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)    \n",
        "    \n",
        "fix_random(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVCaVMrZU2l"
      },
      "source": [
        "#PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWbdix6EZUJX",
        "outputId": "925a6246-9236-404b-c47e-3018a4e1dfb7"
      },
      "source": [
        "def download_dataset(download_path: str, url: str):  # download dataset\n",
        "    if not os.path.exists(download_path):\n",
        "        print(\"Downloading dataset...\")\n",
        "        request.urlretrieve(url, download_path)\n",
        "        print(\"Download complete!\")\n",
        "\n",
        "\n",
        "def extract_dataset(download_path: str, extract_path: str):  # extract dataset\n",
        "    print(\"Extracting dataset... (it may take a while...)\")\n",
        "    with zipfile.ZipFile(download_path, 'r') as loaded_zip:\n",
        "        loaded_zip.extractall(extract_path)\n",
        "    print(\"Extraction completed!\")\n",
        "\n",
        "\n",
        "def encode_dataset(dataset_path: str, dataset_folder: str, debug: bool = True) -> (\n",
        "        pd.DataFrame, int):  # dataset to dataframe\n",
        "    dataframe_rows = []\n",
        "    s_lengths = []\n",
        "    for index, file in tqdm(enumerate(sorted(os.listdir(dataset_path)))):\n",
        "        file_name = os.path.join(dataset_path, file)\n",
        "        with open(file_name) as f:\n",
        "            lines = f.readlines()\n",
        "        full_file = ''.join(lines)  # since lines is a list we use a single string called full_file\n",
        "\n",
        "        #LRB RRB COPY FROM ASSIGNMENT 2\n",
        "        #######  deletes all puntuation #\n",
        "        #full_file = re.sub(r'[^\\w\\s]', r'\\.', full_file) #replace all puntuaction with period\n",
        "        ############################################\n",
        "\n",
        "        full_file = re.sub(r'(\\t\\d+)', '', full_file)  # remove numbers from each lines of dataset\n",
        "        full_file = re.sub(r'(\\t)', ' ', full_file)  # replace \\t with a space\n",
        "        sentences = full_file.split('\\n\\n')\n",
        "        for s in sentences:  # separate all words from their tags\n",
        "            text = ''.join(re.findall(r'.+ ', s))\n",
        "            labels = ''.join(re.findall(r' .+', s))\n",
        "            labels = re.sub(r' (.+)', r'\\1 ', labels)\n",
        "            labels = re.sub('\\n', ' ', labels)\n",
        "            s_lengths.append(len(labels.split(' ')))\n",
        "            # split into train, val and test\n",
        "            if index <= 100:\n",
        "                split = 'train'\n",
        "            elif 100 < index <= 150:\n",
        "                split = 'val'\n",
        "            else:\n",
        "                split = 'test'\n",
        "\n",
        "            # create a single row of dataframe\n",
        "            dataframe_row = {\n",
        "                \"text\": text,\n",
        "                \"POStagging\": labels,\n",
        "                \"split\": split,\n",
        "            }\n",
        "            dataframe_rows.append(dataframe_row)\n",
        "\n",
        "    # transform the list of rows in a proper dataframe\n",
        "    df = pd.DataFrame(dataframe_rows)\n",
        "    df = df[[\"text\",\n",
        "             \"POStagging\",\n",
        "             \"split\"]]\n",
        "    dataframe_path = os.path.join(dataset_folder, \"dependency_treebank_df.pkl\")\n",
        "    df.to_pickle(dataframe_path)\n",
        "    return df, max(s_lengths)\n",
        "\n",
        "\n",
        "def create_dataset():\n",
        "    dataset_folder = os.path.join(os.getcwd(), \"Datasets\")\n",
        "    if not os.path.exists(dataset_folder):\n",
        "        os.makedirs(dataset_folder)\n",
        "\n",
        "    url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
        "\n",
        "    dataset_path_zip = os.path.join(dataset_folder, \"dependency_treebank.zip\")\n",
        "    download_dataset(dataset_path_zip, url)\n",
        "    extract_dataset(dataset_path_zip, dataset_folder)\n",
        "    dataset_path = os.path.join(dataset_folder, \"dependency_treebank\")\n",
        "    df, max_seq_len = encode_dataset(dataset_path, dataset_folder)\n",
        "    df['POStagging'] = df['POStagging'].str.lower()\n",
        "    df['text'] = df['text'].str.lower()\n",
        "    return df, max_seq_len\n",
        "\n",
        "\n",
        "def create_trainable(dataset, value_to_key, max_seq_len, num_classes):\n",
        "    text_ids = [[value_to_key[word] for word in sen.split()] for sen in dataset['text']]\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    label_tokenizer = {}\n",
        "\n",
        "    one_hot_idx = 0\n",
        "    for sen, tagging in zip(text_ids, dataset[\"POStagging\"]):\n",
        "        tmp = [0] * (max_seq_len - len(sen)) + sen\n",
        "        x_train.append(tmp)\n",
        "\n",
        "        for label in tagging.split():\n",
        "            try:\n",
        "                check_label = label_tokenizer[label]\n",
        "            except KeyError:\n",
        "                label_tokenizer[label] = [1 if i == one_hot_idx else 0 for i in range(num_classes)]\n",
        "                one_hot_idx += 1\n",
        "\n",
        "        tmp = [[0] * num_classes] * (max_seq_len - len(sen)) + [label_tokenizer[e] for e in tagging.split()]\n",
        "        y_train.append(tmp)\n",
        "    return np.array(x_train), np.array(y_train), label_tokenizer\n",
        "\n",
        "\n",
        "def get_num_classes(dataset):\n",
        "    return len(np.unique(''.join(dataset[\"POStagging\"]).split())) + 1  # +1 for the padding\n",
        "\n",
        "#########################################\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB=True\n",
        "except:\n",
        "    IN_COLAB=False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"We're running Colab\")\n",
        "    # Mount the Google Drive at mount\n",
        "    mount='/content/gdrive'\n",
        "    print(\"Colab: mounting Google drive on \", mount)\n",
        "    drive.mount(mount)\n",
        "\n",
        "    # Switch to the directory on the Google Drive that you want to use\n",
        "    drive_root = mount + \"/My Drive/NLP/Assignment1\"\n",
        "    \n",
        "    # Create drive_root if it doesn't exist\n",
        "    create_drive_root = True\n",
        "    if create_drive_root:\n",
        "        print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
        "        os.makedirs(drive_root, exist_ok=True)\n",
        "    \n",
        "    # Change to the directory\n",
        "    print(\"\\nColab: Changing directory to \", drive_root)\n",
        "    %cd $drive_root\n",
        "    print(\"Checking working directory:\")\n",
        "    %pwd\n",
        "\n",
        "# download_data('dataset')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're running Colab\n",
            "Colab: mounting Google drive on  /content/gdrive\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "Colab: making sure  /content/gdrive/My Drive/NLP/Assignment1  exists.\n",
            "\n",
            "Colab: Changing directory to  /content/gdrive/My Drive/NLP/Assignment1\n",
            "/content/gdrive/My Drive/NLP/Assignment1\n",
            "Checking working directory:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f906py0bZ58D"
      },
      "source": [
        "#CLASSES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WIn6xeVaDbI"
      },
      "source": [
        "##Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDUaYlImZ89v"
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, dataset_sentences, embedding_dim, glove_dict, glove_matrix):\n",
        "        self.embedding_matrix = None\n",
        "        self.value_to_key = {}\n",
        "        self.value_to_key_new = {}\n",
        "        self.key_to_value = {}\n",
        "        self.num_unique_words = 0\n",
        "        self.dataset_sentences = dataset_sentences\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.glove_dict = glove_dict\n",
        "        self.glove_matrix = glove_matrix\n",
        "        self.unique_words = set()\n",
        "\n",
        "    def get_val_to_key(self):\n",
        "        return copy.deepcopy(self.value_to_key)\n",
        "\n",
        "    def tokenize(self):\n",
        "        self.value_to_key_new = {}\n",
        "        unique_words = set()\n",
        "        for sen in self.dataset_sentences:\n",
        "            for w in sen.split():\n",
        "                unique_words.add(w)  # get se of unique words\n",
        "        new_unique = unique_words - self.unique_words\n",
        "        for i, word in enumerate(new_unique):\n",
        "            if self.embedding_matrix is not None:\n",
        "                self.key_to_value[i + len(self.embedding_matrix)] = word  # build two dictionaries for key value correspondence\n",
        "                self.value_to_key[word] = i + len(self.embedding_matrix)\n",
        "            else:\n",
        "                self.key_to_value[i] = word  # build two dictionaries for key value correspondence\n",
        "                self.value_to_key[word] = i\n",
        "            self.value_to_key_new[word] = i\n",
        "\n",
        "        self.num_unique_words = len(new_unique)\n",
        "        self.unique_words = self.unique_words | new_unique  # union of unique words and new unique words\n",
        "\n",
        "\n",
        "    def __build_embedding_matrix_glove(self):\n",
        "        oov_words = []\n",
        "        tmp_embedding_matrix = np.zeros((self.num_unique_words, self.embedding_dim), dtype=np.float32)\n",
        "        len_old_emb_matrix = len(self.embedding_matrix) if self.embedding_matrix is not None else 0\n",
        "        for word, idx in tqdm(self.value_to_key_new.items()):\n",
        "            try:\n",
        "                embedding_vector = self.glove_matrix[self.glove_dict[word]]\n",
        "                tmp_embedding_matrix[idx] = embedding_vector\n",
        "            except (KeyError, TypeError):\n",
        "                oov_words.append((word, idx + len_old_emb_matrix))\n",
        "        if self.embedding_matrix is not None:\n",
        "            self.embedding_matrix = np.vstack((self.embedding_matrix, tmp_embedding_matrix))\n",
        "        else:\n",
        "            self.embedding_matrix = tmp_embedding_matrix\n",
        "        return oov_words\n",
        "\n",
        "    def build_embedding_matrix(self):\n",
        "        oov_words = self.__build_embedding_matrix_glove()\n",
        "        for word, idx in oov_words:\n",
        "            neighbour_words = []\n",
        "            for sen in self.dataset_sentences:  # look for word in sentence\n",
        "                for i, wanted_word in enumerate(sen):\n",
        "                    if wanted_word == word:\n",
        "                        neighbour_words.append(sen[i - 1])  # append previous word in list of neighbours\n",
        "                        neighbour_words.append(sen[i + 1])  # append next word in list of neighbours\n",
        "            avg_matrix = np.zeros((len(neighbour_words), self.embedding_dim))  # initialize matrix of avgs\n",
        "\n",
        "            length_in_vocab = 0  # to check if neighbours are OOV\n",
        "            for i, el in enumerate(neighbour_words):\n",
        "                try:\n",
        "                    avg_matrix[i] = self.embedding_matrix[self.value_to_key[el]]  # check not OOV\n",
        "                    length_in_vocab += 1  # we don't want to use the zero columns of avg_matrix\n",
        "                except (KeyError, TypeError):  # the model doesn't exist\n",
        "                    pass\n",
        "            if length_in_vocab == 0:\n",
        "                embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=self.embedding_dim)\n",
        "            else:\n",
        "                embedding_vector = np.mean(avg_matrix[:length_in_vocab], axis=0)\n",
        "            self.embedding_matrix[idx] = embedding_vector\n",
        "        return copy.deepcopy(self.embedding_matrix)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgyHeGTHaHEW"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACllxoPkaHNp"
      },
      "source": [
        "class Model(object):\n",
        "    def __init__(self, model_type, compile_info, value_to_key, embedding_dim, max_seq_len, num_labels,\n",
        "                 embedding_matrix):\n",
        "\n",
        "        self.compile_info = compile_info\n",
        "        self.value_to_key = value_to_key\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.num_labels = num_labels\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "\n",
        "        if 'baseline' == model_type:\n",
        "            self.model = self.create_LSTM()\n",
        "        elif 'gru' == model_type:\n",
        "            self.model = self.create_GRU()\n",
        "        elif 'two_lstm' == model_type:\n",
        "            self.model = self.create_two_LSTM()\n",
        "        else:\n",
        "            self.model = self.create_two_Dense()\n",
        "\n",
        "\n",
        "    def create_LSTM(self) -> keras.Model:\n",
        "\n",
        "        bidirect_model = keras.models.Sequential()\n",
        "        bidirect_model.add(layers.Embedding(input_dim=len(self.value_to_key.keys()),\n",
        "                                            output_dim=self.embedding_dim,\n",
        "                                            input_length=self.max_seq_len,\n",
        "                                            mask_zero=True,\n",
        "                                            weights=[self.embedding_matrix],\n",
        "                                            trainable=False\n",
        "                                            ))\n",
        "        bidirect_model.add(layers.Bidirectional(layers.LSTM(250, return_sequences=True)))\n",
        "        bidirect_model.add(layers.TimeDistributed(layers.Dense(self.num_labels, activation=\"softmax\")))\n",
        "\n",
        "        bidirect_model.compile(**self.compile_info)\n",
        "        bidirect_model.summary()\n",
        "        return bidirect_model\n",
        "\n",
        "    def create_GRU(self) -> keras.Model:\n",
        "        gru = keras.models.Sequential()\n",
        "        gru.add(layers.Embedding(input_dim=len(self.value_to_key.keys()),\n",
        "                                 output_dim=self.embedding_dim,\n",
        "                                 input_length=self.max_seq_len,\n",
        "                                 mask_zero=True,\n",
        "                                 weights=[self.embedding_matrix],\n",
        "                                 trainable=False\n",
        "                                 ))\n",
        "\n",
        "        gru.add(layers.GRU(64, return_sequences=True))\n",
        "        gru.add(layers.TimeDistributed(layers.Dense(self.num_labels, activation=\"softmax\")))\n",
        "        gru.compile(**self.compile_info)\n",
        "        gru.summary()\n",
        "        return gru\n",
        "\n",
        "    def create_two_LSTM(self) -> keras.Model:\n",
        "        lstm = keras.models.Sequential()\n",
        "        lstm.add(layers.Embedding(input_dim=len(self.value_to_key.keys()),\n",
        "                                  output_dim=self.embedding_dim,\n",
        "                                  input_length=self.max_seq_len,\n",
        "                                  mask_zero=True,\n",
        "                                  weights=[self.embedding_matrix],\n",
        "                                  trainable=False\n",
        "                                  ))\n",
        "\n",
        "        lstm.add(layers.Bidirectional(layers.LSTM(250, return_sequences=True)))\n",
        "        lstm.add(layers.LSTM(64, return_sequences=True))\n",
        "        lstm.add(layers.TimeDistributed(layers.Dense(self.num_labels, activation=\"softmax\")))\n",
        "        lstm.compile(**self.compile_info)\n",
        "        lstm.summary()\n",
        "        return lstm\n",
        "\n",
        "    def create_two_Dense(self) -> keras.Model:\n",
        "        lstm = keras.models.Sequential()\n",
        "        lstm.add(layers.Embedding(input_dim=len(self.value_to_key.keys()),\n",
        "                                  output_dim=self.embedding_dim,\n",
        "                                  input_length=self.max_seq_len,\n",
        "                                  mask_zero=True,\n",
        "                                  weights=[self.embedding_matrix],\n",
        "                                  trainable=False\n",
        "                                  ))\n",
        "\n",
        "        lstm.add(layers.Bidirectional(layers.LSTM(250, return_sequences=True)))\n",
        "        lstm.add(layers.TimeDistributed(layers.Dense(128, activation=\"relu\")))\n",
        "        lstm.add(layers.TimeDistributed(layers.Dense(self.num_labels, activation=\"softmax\")))\n",
        "        lstm.compile(**self.compile_info)\n",
        "        lstm.summary()\n",
        "        return lstm\n",
        "\n",
        "    def show_history(self, history: keras.callbacks.History):\n",
        "\n",
        "        history_data = history.history\n",
        "        print(\"Displaying the following history keys: \", history_data.keys())\n",
        "\n",
        "        for key, value in history_data.items():\n",
        "            if not key.startswith('val'):\n",
        "                fig, ax = plt.subplots(1, 1)\n",
        "                ax.set_title(key)\n",
        "                ax.plot(value)\n",
        "                if 'val_{}'.format(key) in history_data:\n",
        "                    ax.plot(history_data['val_{}'.format(key)])\n",
        "                else:\n",
        "                    print(\"Couldn't find validation values for metric: \", key)\n",
        "\n",
        "                ax.set_ylabel(key)\n",
        "                ax.set_xlabel('epoch')\n",
        "                ax.legend(['train', 'val'], loc='best')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    def train_model(self,\n",
        "                    x_train: np.ndarray,\n",
        "                    y_train: np.ndarray,\n",
        "                    x_val: np.ndarray,\n",
        "                    y_val: np.ndarray,\n",
        "                    training_info: dict):\n",
        "\n",
        "        print(\"Start training! \\nParameters: {}\".format(training_info))\n",
        "        history = self.model.fit(x=x_train, y=y_train,\n",
        "                                 validation_data=(x_val, y_val),\n",
        "                                 **training_info)\n",
        "        print(\"Training completed! Showing history...\")\n",
        "\n",
        "        self.show_history(history)\n",
        "\n",
        "    def predict_data(self,\n",
        "                      x: np.ndarray,\n",
        "                      prediction_info: dict) -> np.ndarray:\n",
        "\n",
        "        print('Starting prediction: \\n{}'.format(prediction_info))\n",
        "        print('Predicting on {} samples'.format(x.shape[0]))\n",
        "\n",
        "        predictions = self.model.predict(x, **prediction_info)\n",
        "        return predictions"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePav_t9Ham6U"
      },
      "source": [
        "#MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXHka6Viamc6",
        "outputId": "2eb46dbb-3954-42d3-ef07-9aef0bdc9612"
      },
      "source": [
        "df, max_seq_len = create_dataset()\n",
        "\n",
        "try:\n",
        "    with open(f\"glove-{EMBEDDING_DIMENSION}.pkl\", 'rb') as f:\n",
        "            emb_model = pickle.load(f)\n",
        "except Exception:\n",
        "    emb_model = gloader.load(f\"glove-wiki-gigaword-{EMBEDDING_DIMENSION}\")\n",
        "    with open(f\"glove-{EMBEDDING_DIMENSION}.pkl\", 'wb') as f:\n",
        "        pickle.dump(emb_model, f)\n",
        "\n",
        "    glove_dict = emb_model.key_to_index\n",
        "    glove_matrix = emb_model.vectors\n",
        "\n",
        "tokenizer = Tokenizer(df[df['split'] == 'train']['text'], EMBEDDING_SIZE, glove_dict, glove_matrix)\n",
        "tokenizer.tokenize()\n",
        "v2_val_to_key = tokenizer.get_val_to_key()\n",
        "v2_matrix = tokenizer.build_embedding_matrix()\n",
        "\n",
        "tokenizer.dataset_sentences = df[df['split'] == 'val']['text']\n",
        "tokenizer.tokenize()\n",
        "v3_matrix = tokenizer.build_embedding_matrix()\n",
        "v3_val_to_key = tokenizer.get_val_to_key()\n",
        "\n",
        "tokenizer.dataset_sentences = df[df['split'] == 'test']['text']\n",
        "tokenizer.tokenize()\n",
        "v4_matrix = tokenizer.build_embedding_matrix()\n",
        "v4_val_to_key = tokenizer.get_val_to_key()\n",
        "\n",
        "num_classes = get_num_classes(df[df['split'] == 'train'])\n",
        "x_train, y_train, tok = create_trainable(df[df['split'] == 'train'], v3_val_to_key, max_seq_len,\n",
        "                                         num_classes=num_classes)\n",
        "x_val, y_val, tok = create_trainable(df[df['split'] == 'val'], v3_val_to_key, max_seq_len, num_classes=num_classes)\n",
        "x_test, y_test, tok = create_trainable(df[df['split'] == 'test'], v4_val_to_key, max_seq_len, num_classes=num_classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset... (it may take a while...)\n",
            "Extraction completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "199it [00:00, 330.21it/s]\n",
            "100%|██████████| 7481/7481 [00:00<00:00, 486942.30it/s]\n",
            "100%|██████████| 2434/2434 [00:00<00:00, 320521.68it/s]\n",
            "100%|██████████| 1032/1032 [00:00<00:00, 750697.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s99TcYeDa1y9"
      },
      "source": [
        "#TRAIN VARIOUS MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y1w997vca49D",
        "outputId": "d92c242a-0247-4852-9111-af205aa9a642"
      },
      "source": [
        "compile_info = {\n",
        "    'optimizer': keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    'loss': 'categorical_crossentropy',\n",
        "    'metrics': ['accuracy']\n",
        "}\n",
        "\n",
        "training_info = {\n",
        "    'verbose': 1,\n",
        "    'epochs': 1,\n",
        "    'batch_size': 64,\n",
        "    'callbacks': [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                patience=10)]\n",
        "}\n",
        "\n",
        "model_params = {\n",
        "    'compile_info': compile_info,\n",
        "    'value_to_key': v4_val_to_key,\n",
        "    'embedding_dim': EMBEDDING_SIZE,\n",
        "    'max_seq_len': max_seq_len,\n",
        "    'num_labels': num_classes,\n",
        "    'embedding_matrix': v4_matrix\n",
        "}\n",
        "\n",
        "prediction_info = {\n",
        "    'batch_size': 64,\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "# BASELINE\n",
        "baseline = Model('baseline', compile_info, v4_val_to_key, EMBEDDING_SIZE, max_seq_len,\n",
        "                 num_labels=num_classes, embedding_matrix=v4_matrix)\n",
        "baseline_train = baseline.train_model(x_train=x_train, y_train=y_train,\n",
        "                             x_val=x_val, y_val=y_val, training_info=training_info)\n",
        "\n",
        "# GRU\n",
        "#gru_model = Model('gru', compile_info, v3_val_to_key, EMBEDDING_SIZE, max_seq_len,\n",
        "                   #          num_labels=num_classes, embedding_matrix=v3_matrix)\n",
        "\n",
        "#gru_train_model = Model.train_model(x_train=x_train, y_train=y_train,\n",
        "                      #              x_val=x_val, y_val=y_val, training_info=training_info)\n",
        "\n",
        "# TWO LSTM\n",
        "'''twolstm_model = Model('two_lstm', compile_info, v3_val_to_key, EMBEDDING_SIZE, max_seq_len,\n",
        "                                      num_labels=num_classes, embedding_matrix=v3_matrix)\n",
        "                                      \n",
        "twolstm_train_model = Model.train_model(x_train=x_train, y_train=y_train,\n",
        "        x_val=x_val, y_val=y_val, training_info=training_info)\n",
        "\n",
        "# TWO DENSE\n",
        "twodense_model = Model('two_dense', compile_info, v3_val_to_key, EMBEDDING_SIZE, max_seq_len,\n",
        "                                        num_labels=num_classes, embedding_matrix=v3_matrix)\n",
        "\n",
        "twodense_train_model = Model.train_model(x_train=x_train, y_train=y_train,\n",
        "                                    x_val=x_val, y_val=y_val, training_info=training_info)'''\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 250, 50)           547350    \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 250, 500)         602000    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 250, 46)          23046     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,172,396\n",
            "Trainable params: 625,046\n",
            "Non-trainable params: 547,350\n",
            "_________________________________________________________________\n",
            "Start training! \n",
            "Parameters: {'verbose': 1, 'epochs': 1, 'batch_size': 64, 'callbacks': [<keras.callbacks.EarlyStopping object at 0x7f4e8d77c0d0>]}\n",
            "31/31 [==============================] - 32s 819ms/step - loss: 0.3199 - accuracy: 0.1383 - val_loss: 0.3468 - val_accuracy: 0.0739\n",
            "Training completed! Showing history...\n",
            "Displaying the following history keys:  dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting prediction: \n",
            "{'batch_size': 64, 'verbose': 1}\n",
            "Predicting on 644 samples\n",
            "11/11 [==============================] - 5s 154ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-791fb63f6a5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# from one hot to label index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-0ZF_-txf19"
      },
      "source": [
        "#EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF91AoyqxlqS"
      },
      "source": [
        "#funzione per togliere la punteggiatura"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOYgCry6xZ6A"
      },
      "source": [
        "#bisogna togliere la punteggiatura\n",
        "y_pred = baseline.predict_data(x_test, prediction_info=prediction_info)\n",
        "y_pred = [np.argmax(el) for el in y_pred]  # from one hot to label index\n",
        "y_true = [np.argmax(el) for el in y_test]\n",
        "f1_score = f1_score(y_true, y_pred, average='macro')\n",
        "print(f1_score)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}